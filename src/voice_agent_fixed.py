"""
Fixed Voice AI Agent with resolved audio duplication issues
"""

import asyncio
import websockets
import json
import base64
import pyaudio
import threading
import queue
import time
from typing import Dict, List, Callable, Any
import os
from dotenv import load_dotenv

load_dotenv()

class VoiceAIAgentFixed:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        self.ws = None
        self.audio = pyaudio.PyAudio()
        self.is_recording = False
        self.is_playing = False
        
        # Audio settings
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 24000
        self.chunk = 1024
        
        # Audio queue for thread-safe communication
        self.audio_queue = queue.Queue()
        
        # Response tracking to prevent duplicates
        self.last_response_id = None
        self.active_responses = set()
        
        # Function registry for HRI commands
        self.functions: Dict[str, Callable] = {}
        self.function_schemas: List[Dict] = []
        
    def register_function(self, name: str, func: Callable, schema: Dict):
        """Register a function that can be called by the AI agent"""
        self.functions[name] = func
        self.function_schemas.append({
            "type": "function",
            "name": name,
            "description": schema.get("description", ""),
            "parameters": schema.get("parameters", {})
        })
        
    async def connect(self):
        """Connect to OpenAI Realtime API"""
        uri = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
        headers = [
            ("Authorization", f"Bearer {self.api_key}"),
            ("OpenAI-Beta", "realtime=v1")
        ]
        
        self.ws = await websockets.connect(uri, additional_headers=headers)
        
        # Configure session
        await self.send_session_update()
        
    async def send_session_update(self):
        """Configure the session with tools and settings"""
        session_config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": """You are an intelligent cafe service robot with voice interaction capabilities. 

CORE CAPABILITIES:
1. CAFE ORDERING: Help customers browse menu, place orders, customize items, process payments
2. ROBOT CONTROL: Move around, control LEDs, take photos, scan environment
3. CUSTOMER SERVICE: Provide recommendations, check order status, handle modifications

CONVERSATION GUIDELINES:
- Always be friendly, helpful, and professional
- For ordering: Guide customers through menu, suggest items, confirm details
- For robot control: Confirm movements for safety, explain actions
- Use appropriate functions based on customer requests
- Ask clarifying questions when needed
- Provide clear status updates

Be conversational and natural - you're both a helpful cafe assistant and a capable service robot!""",
                "voice": "alloy",
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500  # Increased to reduce false triggers
                },
                "tools": self.function_schemas
            }
        }
        
        await self.ws.send(json.dumps(session_config))
        
    async def send_audio_chunk(self, audio_data: bytes):
        """Send audio data to the API"""
        if self.ws and not self.is_playing:  # Don't send audio while playing response
            audio_message = {
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(audio_data).decode()
            }
            await self.ws.send(json.dumps(audio_message))
            
    async def process_audio_queue(self):
        """Process audio data from the queue"""
        while True:
            try:
                # Non-blocking queue check
                audio_data = self.audio_queue.get_nowait()
                await self.send_audio_chunk(audio_data)
                self.audio_queue.task_done()
            except queue.Empty:
                # No audio data, wait a bit
                await asyncio.sleep(0.01)
            except Exception as e:
                print(f"Audio queue error: {e}")
                await asyncio.sleep(0.1)
                
    async def handle_messages(self):
        """Handle incoming messages from the API"""
        async for message in self.ws:
            data = json.loads(message)
            await self.process_message(data)
            
    async def process_message(self, data: Dict):
        """Process different types of messages from the API"""
        msg_type = data.get("type")
        
        if msg_type == "response.audio.delta":
            # Play audio response
            audio_data = base64.b64decode(data["delta"])
            await self.play_audio(audio_data)
            
        elif msg_type == "response.function_call_delta":
            # Handle function calling
            if data.get("delta"):
                await self.handle_function_call(data)
                
        elif msg_type == "response.created":
            response_id = data.get("response", {}).get("id")
            if response_id:
                self.active_responses.add(response_id)
                print("üé§ Processing your request...")
                
        elif msg_type == "response.done":
            response_id = data.get("response", {}).get("id")
            if response_id and response_id in self.active_responses:
                self.active_responses.remove(response_id)
                print("‚úÖ Response ready")
            
        elif msg_type == "response.audio.done":
            # Audio response finished
            self.is_playing = False
            print("üîä Audio playback completed")
            
        elif msg_type == "error":
            print(f"‚ùå Error: {data}")
            
        elif msg_type == "session.created":
            print("‚úÖ Session created successfully")
            
        elif msg_type == "session.updated":
            print("‚úÖ Session configured")
            
        elif msg_type == "input_audio_buffer.speech_started":
            print("üé§ Speech detected...")
            
        elif msg_type == "input_audio_buffer.speech_stopped":
            print("üé§ Processing speech...")
            
    async def handle_function_call(self, data: Dict):
        """Execute function calls from the AI"""
        function_name = data.get("name")
        arguments = data.get("arguments", "{}")
        
        try:
            args = json.loads(arguments)
            if function_name in self.functions:
                print(f"\nüîß Executing: {function_name}")
                if args:
                    print(f"üìã Parameters: {args}")
                result = await self.functions[function_name](**args)
                print(f"‚úÖ Result: {result}\n")
                
                # Send function result back
                response = {
                    "type": "conversation.item.create",
                    "item": {
                        "type": "function_call_output",
                        "call_id": data.get("call_id"),
                        "output": str(result)
                    }
                }
                await self.ws.send(json.dumps(response))
                
        except Exception as e:
            print(f"‚ùå Function call error: {e}")
            
    def start_recording(self):
        """Start recording audio from microphone"""
        self.is_recording = True
        
        def record():
            stream = None
            try:
                stream = self.audio.open(
                    format=self.format,
                    channels=self.channels,
                    rate=self.rate,
                    input=True,
                    frames_per_buffer=self.chunk
                )
                
                print("üé§ Recording started - speak naturally!")
                
                while self.is_recording:
                    try:
                        data = stream.read(self.chunk, exception_on_overflow=False)
                        # Only queue audio if not currently playing response
                        if not self.is_playing:
                            self.audio_queue.put(data)
                    except Exception as e:
                        print(f"Recording error: {e}")
                        break
                        
            except Exception as e:
                print(f"Audio setup error: {e}")
            finally:
                if stream:
                    stream.stop_stream()
                    stream.close()
                print("üé§ Recording stopped")
            
        self.record_thread = threading.Thread(target=record, daemon=True)
        self.record_thread.start()
        
    def stop_recording(self):
        """Stop recording audio"""
        self.is_recording = False
        if hasattr(self, 'record_thread'):
            self.record_thread.join(timeout=2.0)
            
    async def play_audio(self, audio_data: bytes):
        """Play audio data through speakers"""
        if len(audio_data) == 0:
            return
            
        self.is_playing = True  # Set flag to prevent recording feedback
        
        def play():
            try:
                stream = self.audio.open(
                    format=self.format,
                    channels=self.channels,
                    rate=self.rate,
                    output=True
                )
                
                stream.write(audio_data)
                stream.stop_stream()
                stream.close()
                
            except Exception as e:
                print(f"Audio playback error: {e}")
            finally:
                # Small delay to prevent immediate re-recording
                time.sleep(0.1)
                
        threading.Thread(target=play, daemon=True).start()
        
    async def run(self):
        """Main loop for the voice agent"""
        try:
            print("üîó Connecting to OpenAI Realtime API...")
            await self.connect()
            
            # Start recording
            self.start_recording()
            
            # Start audio queue processor
            audio_task = asyncio.create_task(self.process_audio_queue())
            
            print("\nüéâ Voice AI Cafe Robot is ready!")
            print("üé§ Speak naturally - I can help with cafe orders and robot control!")
            print("üí° Try saying: 'Hello, show me the menu' or 'Move forward 2 meters'")
            print("‚èπÔ∏è  Press Ctrl+C to stop\n")
            
            # Handle messages
            await self.handle_messages()
            
        except websockets.exceptions.ConnectionClosed:
            print("üîå Connection closed")
        except KeyboardInterrupt:
            print("\nüëã Stopped by user")
        finally:
            self.stop_recording()
            if 'audio_task' in locals():
                audio_task.cancel()
            
    def cleanup(self):
        """Clean up resources"""
        self.stop_recording()
        self.audio.terminate()
        if self.ws:
            asyncio.create_task(self.ws.close())